import re
import json
import glob
import os
from collections import defaultdict

# 1. í‚¤ì›Œë“œ ë§µ (ëª©ì°¨ ê´€ë ¨ í‚¤ì›Œë“œ ì œê±°ë¨, ê³µë°± ì œê±°ëœ ë§¤ì¹­ í‚¤ì›Œë“œë¡œ ìˆ˜ì •)
CATEGORY_MAP = {
    'ìš”ì•½': ['ìš”ì•½', 'í•µì‹¬ê¸°ìˆ ', 'ì£¼ê°„ì¤‘ì '], # [ìˆ˜ì •] 'ìš” ì•½'->'ìš”ì•½' (detect_categoryì—ì„œ ê³µë°± ì œê±°í•˜ë¯€ë¡œ)
    'ê¸°ìƒ': ['ê¸°ìƒ', 'ì „ë§', 'ë‚ ì”¨', 'ì €ìˆ˜ìœ¨', 'ê°•ìˆ˜ëŸ‰', 'ë†ì—…ì •ë³´', 'ë†ì—…ì •ë³´'],
    'ë²¼': ['ë²¼', 'ë³ì”¨', 'ëª¨ë‚´ê¸°', 'ìŒ€', 'ì‹ëŸ‰ìž‘ë¬¼', 'ì´ì•™', 'ë…¼'],
    'ë°­ìž‘ë¬¼': ['ë°­ìž‘ë¬¼', 'ì½©', 'ê°ìž', 'ê³ êµ¬ë§ˆ', 'ë³´ë¦¬', 'ë°€', 'ì˜¥ìˆ˜ìˆ˜', 'ë‘ë¥˜', 'ìž¡ê³¡', 'ë§¥ë¥˜'],
    'ì±„ì†Œ': ['ì±„ì†Œ', 'ê³ ì¶”', 'ë§ˆëŠ˜', 'ì–‘íŒŒ', 'ë°°ì¶”', 'ë¬´', 'ì‹œì„¤í•˜ìš°ìŠ¤', 'ë”¸ê¸°', 'ìˆ˜ë°•', 'ì˜¤ì´', 'í† ë§ˆí† ', 'ì›ì˜ˆ'],
    'ê³¼ìˆ˜': ['ê³¼ìˆ˜', 'ì‚¬ê³¼', 'ë°°', 'í¬ë„', 'ë³µìˆ­ì•„', 'ê°ê·¤', 'ë‹¨ê°', 'ìžë‘', 'ê³¼ì›', 'ë™í•´', 'ê½ƒëˆˆ'],
    'í™”í›¼': ['í™”í›¼', 'êµ­í™”', 'ìž¥ë¯¸', 'í”„ë¦¬ì§€ì•„', 'ì¹´ë„¤ì´ì…˜', 'ê½ƒ'],
    'íŠ¹ìš©ìž‘ë¬¼': ['íŠ¹ìš©ìž‘ë¬¼', 'ì¸ì‚¼', 'ì˜¤ë¯¸ìž', 'ì•½ìš©ìž‘ë¬¼', 'ë²„ì„¯', 'ëŠíƒ€ë¦¬', 'ë‹¹ê·€'],
    'ì¶•ì‚°': ['ì¶•ì‚°', 'í•œìš°', 'ë¼ì§€', 'ë‹­', 'AI', 'êµ¬ì œì—­', 'ê°€ì¶•', 'ë°©ì—­', 'ì†Œ', 'ì –ì†Œ', 'ì–‘ëˆ', 'ê°€ê¸ˆ', 'ëˆì‚¬', 'ê³„ì‚¬'],
    'ì–‘ë´‰': ['ì–‘ë´‰', 'ë²Œí†µ', 'ê¿€ë²Œ', 'ë²Œì§‘', 'ë´‰êµ°', 'ë§ë²Œ', 'ì‘ì• ', 'ì›”ë™ë²Œ', 'ìž¥ìˆ˜ë§ë²Œ', 'ë“±ê²€ì€ë§ë²Œ', 'í•©ë´‰', 'ì‚¬ì–‘ê¸°']
}

def detect_category(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ì°¾ê¸° (ëª©ì°¨ í•„í„°ë§ í¬í•¨)"""
    # 0. ëª©ì°¨ í•„í„°ë§ ìš°ì„  ì ìš©
    if 'ëª©ì°¨' in text or 'ëª© ì°¨' in text:
        return 'SKIP'
        
    clean_text = text.replace(" ", "")
    for category, keywords in CATEGORY_MAP.items():
        for keyword in keywords:
            if keyword in clean_text:
                return category
    return 'ê¸°íƒ€'

def parse_md_to_jsonl_robust(directory_path):
    # json_con í´ë” ë‚´ì˜ md íŒŒì¼ë§Œ íƒ€ê²ŸíŒ… (ìœ ì € ìš”ì²­ì— ë”°ë¼)
    target_path = os.path.join(directory_path, "json_con", "*.md")
    md_files = glob.glob(target_path)
    
    # ë§Œì•½ json_conì— ì—†ìœ¼ë©´ í˜„ìž¬ ë””ë ‰í† ë¦¬ë„ ê²€ìƒ‰
    if not md_files:
        md_files = glob.glob(os.path.join(directory_path, "*.md"))

    all_weeks_data = []

    # í—¤ë” íŒ¨í„´: # [2024-01-01~2024-01-07] ì œëª©
    header_pattern = re.compile(r'^#\s*\[(\d{4}-\d{2}-\d{2}~\d{4}-\d{2}-\d{2})\]\s*(.*)')

    print(f"ðŸ“‚ ë°œê²¬ëœ íŒŒì¼: {len(md_files)}ê°œ")

    for file_path in md_files:
        print(f"   -> ì²˜ë¦¬ ì¤‘: {os.path.basename(file_path)}")
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
        except Exception as e:
            print(f"   âš ï¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            continue

        temp_storage = defaultdict(lambda: defaultdict(list))
        
        current_date_key = None
        current_category = 'ê¸°íƒ€'
        skip_current_section = False

        for line in lines:
            stripped_line = line.strip()
            if not stripped_line: continue

            # 1. í—¤ë” ë¼ì¸ì¸ì§€ í™•ì¸
            match = header_pattern.match(stripped_line)
            
            if match:
                date_range = match.group(1)
                title_content = match.group(2)
                
                current_date_key = date_range
                detected_cat = detect_category(title_content)
                
                if detected_cat == 'SKIP':
                    skip_current_section = True
                    current_category = None
                else:
                    skip_current_section = False
                    current_category = detected_cat
            
            else:
                # 2. ë³¸ë¬¸ ë¼ì¸
                if not skip_current_section and current_date_key and current_category:
                    temp_storage[current_date_key][current_category].append(line.strip())

        # 3. ìž„ì‹œ ì €ìž¥ì†Œë¥¼ ë¦¬ìŠ¤íŠ¸ êµ¬ì¡°ë¡œ ë°˜í™˜ (JSONLìš©)
        for date_key, cat_data in temp_storage.items():
            start_date, end_date = date_key.split('~')
            
            week_entry = {
                "id": date_key,
                "year": start_date[:4],
                "month": int(start_date[5:7]),
                "week_range": date_key,
                "content": {}
            }
            
            for cat, texts in cat_data.items():
                week_entry["content"][cat] = "\n".join(texts)
                
            all_weeks_data.append(week_entry)

    # ë‚ ì§œìˆœ ì •ë ¬
    all_weeks_data.sort(key=lambda x: x['id'])
    
    return all_weeks_data

if __name__ == "__main__":
    current_dir = "."
    print(f"ðŸš€ MD -> JSONL ë³€í™˜ ì‹œìž‘ (TOC ì œê±° ë¡œì§ ì ìš©)")
    
    data = parse_md_to_jsonl_robust(current_dir)
    
    # JSONL íŒŒì¼ë¡œ ì €ìž¥ (embed.py ìž…ë ¥ìš©)
    output_file = 'optimized_farming_data_v2.jsonl'
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for entry in data:
            f.write(json.dumps(entry, ensure_ascii=False) + '\n')
            
    print(f"âœ… ë³€í™˜ ì™„ë£Œ: {len(data)}ì£¼ì°¨ ë°ì´í„° ìƒì„±ë¨ -> {output_file}")
